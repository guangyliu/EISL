{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infinite-logistics",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './multi30k_subword/train.bpe.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b7fc6acbc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train.bpe.en'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./multi30k_subword/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf_valid_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlines_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_valid_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf_valid_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './multi30k_subword/train.bpe.en'"
     ]
    }
   ],
   "source": [
    "file_name = 'train.bpe.en'\n",
    "path = './multi30k_subword/'\n",
    "f_valid_en = open(path+file_name)\n",
    "lines_valid = f_valid_en.readlines()\n",
    "f_valid_en.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greatest-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcnt = {}\n",
    "for line in lines_valid:\n",
    "    for word in line.split():\n",
    "        if word in wordcnt.keys():\n",
    "            wordcnt[word] += 1\n",
    "        else:\n",
    "            wordcnt[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "renewable-lounge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list_all = list(wordcnt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-merit",
   "metadata": {},
   "source": [
    "## Synthetical Noise: Sub Blank Shuffle\n",
    "Blank ~ -- 5299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powerful-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "\n",
    "for drop in range(0,55,5):\n",
    "    shuffle = drop / 50.\n",
    "    blank = drop /100.\n",
    "    new_path = \"val/multi30k_mulsbs\"+str(drop)\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    # 除了 train.en 其他文件copy过来\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            sent = line.split()\n",
    "            #开始 blank\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    if random.random()> 0.5: # 一半概率 blank ，一半概率sub\n",
    "                        sent_blank.append('5299')\n",
    "                    else:\n",
    "                        rand = np.random.randint(len(word_list_all))\n",
    "                        sent_blank.append(word_list_all[rand])\n",
    "            word_list = sent_blank\n",
    "            # 完成 drop\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.floor( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-tribe",
   "metadata": {},
   "source": [
    "## Word Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "underlying-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "\n",
    "for drop in range(0,55,5):\n",
    "    shuffle = drop / 100.\n",
    "    blank = drop /100.\n",
    "    new_path = \"val/multi30k_subbpe\"+str(drop)\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    # 除了 train.en 其他文件copy过来\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            sent = line.split()\n",
    "            #开始 sub\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    rand = np.random.randint(len(word_list_all))\n",
    "                    sent_blank.append(word_list_all[rand])\n",
    "            word_list = sent_blank\n",
    "            # 完成 sub\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "\n",
    "for drop in range(0,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    shuffle = drop / 50.\n",
    "    blank = drop /100.\n",
    "    new_path = \"multi30k_mulbds\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            sent = line.split()\n",
    "            \n",
    "            #开始 blank\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    sent_blank.append('unk')\n",
    "            word_list = sent_blank\n",
    "            # 开始 drop\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent1 = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            # 完成 drop\n",
    "            word_list = sent1\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.floor( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "italic-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 340298\n",
      "2 302045\n",
      "3 264332\n",
      "4 226941\n",
      "5 188697\n",
      "6 150129\n",
      "7 113106\n",
      "8 75517\n",
      "9 37655\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(1,10):\n",
    "    new_path = \"multi30k_drop\"+str(drop)\n",
    "    drop_prob = drop  * 0.1\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "affecting-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 397793\n",
      "5 394892\n",
      "10 370088\n",
      "15 352603\n",
      "20 329896\n",
      "25 309223\n",
      "30 291376\n",
      "35 273685\n",
      "40 250221\n",
      "45 233407\n",
      "50 206157\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'wmt18.multi30k.en-de/'\n",
    "for drop in range(40,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    new_path = \"bpe_multi30k_mul\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            drop_num = np.floor(drop_prob * sen_len)\n",
    "\n",
    "            len_left = sen_len - drop_num\n",
    "            \n",
    "            start = np.random.randint(0,len_left)\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                if j >= start and j < start +drop_num:\n",
    "                    continue\n",
    "                sent.append(w)\n",
    "#             sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "oriented-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'wmt18.multi30k.en-de/'\n",
    "for drop in range(0,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    shuffle = drop / 50.\n",
    "    blank = drop /100.\n",
    "    new_path = \"bpe_multi30k_mul\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            # 完成 drop\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    sent_blank.append('unk')\n",
    "            word_list = sent_blank\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.floor( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "suited-netherlands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "tired-electric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "significant-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./multi30k_blank3/train.en 3 377534\n"
     ]
    }
   ],
   "source": [
    "# word blank\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(3,4):\n",
    "    new_path = \"multi30k_blank\"+str(drop)\n",
    "    drop_prob = drop  * 0.1\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent = []\n",
    "            for j,w in enumerate(word_list):\n",
    "                if keep[j]:\n",
    "                    sent.append(w)\n",
    "                else:\n",
    "                    sent.append('unk')\n",
    "    #         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(new_file,drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word shuffle\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(0,1):\n",
    "    new_path = \"multi30k_shuffle\"+str(drop)\n",
    "    drop_prob = drop\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "\n",
    "        for line in lines_valid:\n",
    "            drop_prob = drop\n",
    "            sent = []\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if drop_prob > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    drop_prob = len(word_list) -1\n",
    "                else:\n",
    "                    drop_prob = 0\n",
    "            for i in range(drop_prob):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "    #         for i, word in enumerate(word_list):\n",
    "    #             sent.append(word_list[sort[i]])\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "employed-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle all\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "drop = 'all'\n",
    "\n",
    "new_path = \"multi30k_shuffle\"+str(drop)\n",
    "# List files and directories\n",
    "# in '/home/User/Documents'\n",
    "folder = os.path.exists(new_path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "for file in os.listdir(path):\n",
    "    if file_name in file:\n",
    "        continue\n",
    "    source = os.path.join(path,file)\n",
    "    destination = os.path.join(new_path,file)\n",
    "    if os.path.exists(destination):\n",
    "        continue\n",
    "# Copy the content of\n",
    "# source to destination\n",
    "    dest = shutil.copyfile(source, destination)\n",
    "\n",
    "file = file_name\n",
    "new_file = './'+new_path+'/'+file\n",
    "if os.path.exists(new_file):\n",
    "    os.remove(new_file)\n",
    "with open(new_file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "\n",
    "    for line in lines_valid:\n",
    "        new_word_sent = []\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        for i in range(sen_len):\n",
    "            new_word_sent.append(word_list[sort[i]])\n",
    "        the_file.write(' '.join(new_word_sent)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "indian-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 377534\n",
      "2 377534\n",
      "3 377534\n",
      "4 377534\n",
      "5 377534\n",
      "6 377534\n"
     ]
    }
   ],
   "source": [
    "# word sub\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(1,7):\n",
    "    new_path = \"multi30k_sub\"+str(drop)\n",
    "    drop_prob = drop  * 0.1\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent = []\n",
    "            for j,w in enumerate(word_list):\n",
    "                if keep[j]:\n",
    "                    sent.append(w)\n",
    "                else:\n",
    "                    rand = np.random.randint(len(word_list_all))\n",
    "                    sent.append(word_list_all[rand])\n",
    "    #         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "democratic-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asphalt',\n",
       " 'decorated',\n",
       " 'slo@@',\n",
       " 'benches',\n",
       " 'chers',\n",
       " 'gate',\n",
       " 'collared',\n",
       " 'ka@@',\n",
       " 'set',\n",
       " 'wakeboard',\n",
       " 'dding',\n",
       " 'fabri@@',\n",
       " 'toy',\n",
       " 'c-@@',\n",
       " 'pilot',\n",
       " 'boat',\n",
       " 'spre@@',\n",
       " 'potat@@',\n",
       " 'teeth',\n",
       " 'canal',\n",
       " 'visiting',\n",
       " 'dough',\n",
       " 'coffee',\n",
       " 'condu@@',\n",
       " 'cat',\n",
       " 'leggings']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "olympic-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file numpy as np\n",
    "import os \n",
    "path = \"multi30k_blank2\"\n",
    "drop_prob = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    for line in lines_valid:\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob\n",
    "#         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        sent = []\n",
    "        for j,w in enumerate(word_list):\n",
    "            if keep[j]:\n",
    "                sent.append(w)\n",
    "            else:\n",
    "                sent.append('<blank>')\n",
    "#         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "        the_file.write(' '.join(sent)+'\\n')\n",
    "        sum_len+= len(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "french-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "path = \"multi30k_shuffle3\"\n",
    "drop_prob = 3\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    \n",
    "    for line in lines_valid:\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        if drop_prob > len(word_list) - 1:\n",
    "            if len(word_list)  >= 2 :\n",
    "                drop_prob = len(word_list) -1\n",
    "            else:\n",
    "                drop_prob = 0\n",
    "        for i in range(drop_prob):\n",
    "            tmp = word_list[sort[i]]\n",
    "            word_list[sort[i]] = word_list[sort[i+1]]\n",
    "            word_list[sort[i+1]] = tmp\n",
    "#         for i, word in enumerate(word_list):\n",
    "#             sent.append(word_list[sort[i]])\n",
    "        the_file.write(' '.join(word_list)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "another-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "path = \"multi30k_shuffle8_drop2\"\n",
    "drop_prob = 8\n",
    "drop_prob1 = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    \n",
    "    for line in lines_valid:\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        if drop_prob > len(word_list) - 1:\n",
    "            if len(word_list)  >= 2 :\n",
    "                drop_prob = len(word_list) -1\n",
    "            else:\n",
    "                drop_prob = 0\n",
    "        for i in range(drop_prob):\n",
    "            tmp = word_list[sort[i]]\n",
    "            word_list[sort[i]] = word_list[sort[i+1]]\n",
    "            word_list[sort[i+1]] = tmp\n",
    "#         for i, word in enumerate(word_list):\n",
    "#             sent.append(word_list[sort[i]])\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob1\n",
    "        sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        the_file.write(' '.join(sent)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "institutional-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'leans',\n",
       " 'a',\n",
       " 'hawaiian',\n",
       " 'shirt',\n",
       " 'with',\n",
       " 'over',\n",
       " 'the',\n",
       " 'of',\n",
       " 'pilot',\n",
       " 'boat',\n",
       " 'rail',\n",
       " 'fo@@',\n",
       " 'g',\n",
       " 'and',\n",
       " 'mountains',\n",
       " 'in',\n",
       " 'background',\n",
       " '.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "monthly-discovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man in shorts and a hawaiian shirt leans over the rail of a pilot boat , with fo@@ g and mountains in the background .\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_shuffle(vocab, x, k):   # slight shuffle such that |sigma[i]-i| <= k\n",
    "    base = torch.arange(x.size(0), dtype=torch.float).repeat(x.size(1), 1).t()\n",
    "    inc = (k+1) * torch.rand(x.size())\n",
    "    inc[x == vocab.go] = 0     # do not shuffle the start sentence symbol\n",
    "    inc[x == vocab.pad] = k+1  # do not shuffle end paddings\n",
    "    _, sigma = (base + inc).sort(dim=0)\n",
    "    return x[sigma, torch.arange(x.size(1))]\n",
    "\n",
    "def word_drop(vocab, x, p):     # drop words with probability p\n",
    "    x_ = []\n",
    "    for i in range(x.size(1)):\n",
    "        words = x[:, i].tolist()\n",
    "        keep = np.random.rand(len(words)) > p\n",
    "        keep[0] = True  # do not drop the start sentence symbol\n",
    "        sent = [w for j, w in enumerate(words) if keep[j]]\n",
    "        sent += [vocab.pad] * (len(words)-len(sent))\n",
    "        x_.append(sent)\n",
    "    return torch.LongTensor(x_).t().contiguous().to(x.device)\n",
    "\n",
    "def word_blank(vocab, x, p):     # blank words with probability p\n",
    "    blank = (torch.rand(x.size(), device=x.device) < p) & \\\n",
    "        (x != vocab.go) & (x != vocab.pad)\n",
    "    x_ = x.clone()\n",
    "    x_[blank] = vocab.blank\n",
    "    return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "searching-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = line.split()\n",
    "sen_len = len(word_list)\n",
    "keep = np.random.rand(len(word_list)) > drop_prob\n",
    "sent = [w for j, w in enumerate(word_list) if keep[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "colonial-finnish",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-89e7251eea67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "li=list(range(10))\n",
    "random.shuffle(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "visible-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "a=[1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "egyptian-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "honest-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'train.tgt'\n",
    "f_valid_en = open('./e2e/e2e-dataset/'+file)\n",
    "lines_valid = f_valid_en.readlines()\n",
    "f_valid_en.close()\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "path = \"e2e_blank2\"\n",
    "drop_prob = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    for line in lines_valid:\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob\n",
    "#         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        sent = []\n",
    "        for j,w in enumerate(word_list):\n",
    "            if keep[j]:\n",
    "                sent.append(w)\n",
    "            else:\n",
    "                sent.append('<blank>')\n",
    "#         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "        the_file.write(' '.join(sent)+'\\n')\n",
    "        sum_len+= len(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "moved-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aromi', 'is', 'an', 'English', 'restaurant', 'in', 'the', 'city', 'centre.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "racial-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aromi', 'is', 'an', 'English', 'restaurant', 'in', 'the', 'city', 'centre.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "criminal-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "logits = torch.log_softmax(torch.randn(1, 5),dim=1)*5\n",
    "# Sample soft categorical using reparametrization trick:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "pacific-trauma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.6465,  -2.1335, -12.8090,  -9.1892, -17.3195]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "documentary-athens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.gumbel_softmax(logits, tau=1.4, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-irish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
