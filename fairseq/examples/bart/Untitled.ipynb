{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "framed-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fairseq.models.bart import BARTModel\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "announced-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "#     model_dir = '/home/lptang/fairseq/checkpoints/denoising_bart/shuffle_bleu_iclr/ng_shuffle8_ba_0.0_bleu12_8_lr_1e-06/'\n",
    "    model_file = 'checkpoint_best.pt'\n",
    "    model_dir = '/home/lptang/fairseq/checkpoints/denoising_bart/shuffle/cr_shuffle8_ba_1.0_cetf_8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "another-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dict.de.txt' not in os.listdir(args.model_dir):\n",
    "    shutil.copyfile('/home/lptang/fairseq/multi30k-bin/shuffle3/dict.en.txt',args.model_dir+'dict.en.txt')\n",
    "    shutil.copyfile('/home/lptang/fairseq/multi30k-bin/shuffle3/dict.de.txt',args.model_dir+'dict.de.txt')\n",
    "bart = BARTModel.from_pretrained(\n",
    "    args.model_dir,\n",
    "    checkpoint_file=args.model_file,\n",
    "    data_name_or_path=args.model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "specified-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = bart.eval()\n",
    "bart = bart.cuda().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "experienced-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile='/home/lptang/fairseq/examples/translation/multi30k_shuffle3/test.de'\n",
    "outfile=\"bart_hypo_2.txt\"\n",
    "bsz=32\n",
    "n_obs=None\n",
    "count = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beneficial-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_kwargs = dict(beam=4, lenpen=2.0, max_len_b=30, min_len=2, no_repeat_ngram_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "second-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(infile) as source, open(outfile, \"w\") as fout:\n",
    "        sline = source.readline().strip()\n",
    "        slines = [sline]\n",
    "        for sline in source:\n",
    "            if n_obs is not None and count > n_obs:\n",
    "                break\n",
    "            if count % bsz == 0:\n",
    "                hypotheses_batch = bart.sample(slines, **eval_kwargs)\n",
    "                for hypothesis in hypotheses_batch:\n",
    "                    fout.write(hypothesis + \"\\n\")\n",
    "                    fout.flush()\n",
    "                slines = []\n",
    "\n",
    "            slines.append(sline.strip())\n",
    "            count += 1\n",
    "\n",
    "        if slines != []:\n",
    "            hypotheses_batch = bart.sample(slines, **eval_kwargs)\n",
    "            for hypothesis in hypotheses_batch:\n",
    "                fout.write(hypothesis + \"\\n\")\n",
    "                fout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-fisher",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
