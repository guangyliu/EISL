{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'train.en'\n",
    "f_valid_en = open('./ori_multi30k/'+file_name)\n",
    "lines_valid = f_valid_en.readlines()\n",
    "f_valid_en.close()\n",
    "path = './ori_multi30k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-identifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dying-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcnt = {}\n",
    "for line in lines_valid:\n",
    "    for word in line.split():\n",
    "        if word in wordcnt.keys():\n",
    "            wordcnt[word] += 1\n",
    "        else:\n",
    "            wordcnt[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expressed-flood",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list_all = list(wordcnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "original-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "\n",
    "for drop in range(0,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    shuffle = drop / 50.\n",
    "    blank = drop /100.\n",
    "    new_path = \"multi30k_mulbds\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            sent = line.split()\n",
    "            \n",
    "            #开始 blank\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    sent_blank.append('unk')\n",
    "            word_list = sent_blank\n",
    "            # 开始 drop\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent1 = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            # 完成 drop\n",
    "            word_list = sent1\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.floor( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "biological-genetics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 340298\n",
      "2 302045\n",
      "3 264332\n",
      "4 226941\n",
      "5 188697\n",
      "6 150129\n",
      "7 113106\n",
      "8 75517\n",
      "9 37655\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(1,10):\n",
    "    new_path = \"multi30k_drop\"+str(drop)\n",
    "    drop_prob = drop  * 0.1\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-sucking",
   "metadata": {},
   "source": [
    "# word Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "negative-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13308\n",
      "5 13972\n",
      "10 14598\n",
      "15 15365\n",
      "20 15963\n",
      "25 16683\n",
      "30 17300\n",
      "35 18056\n",
      "40 18591\n",
      "45 19295\n",
      "50 19953\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(0,55,5):\n",
    "    new_path = \"multi30k_rep\"+str(drop)\n",
    "    drop_prob = drop  * 0.01\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or 'ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                sent.append(w)\n",
    "                if not keep[j]:\n",
    "                    sent.append(w)\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-vault",
   "metadata": {},
   "source": [
    "# Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13308\n",
      "5 13966\n",
      "10 14664\n",
      "15 15292\n",
      "20 16026\n",
      "25 16557\n",
      "30 17182\n",
      "35 18004\n",
      "40 18618\n",
      "45 19297\n",
      "50 19946\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "# path = 'ori_multi30k/'\n",
    "for drop in range(0,55,5):\n",
    "    new_path = \"multi30k_ins\"+str(drop)\n",
    "    drop_prob = drop  * 0.01\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or 'ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                sent.append(w)\n",
    "                if not keep[j]:\n",
    "                    sent.append(word_list_all[np.random.randint(0,len(word_list_all))])\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-flight",
   "metadata": {},
   "source": [
    "# MUL  Rep sub blank shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "import copy\n",
    "for drop in range(0,55,5):\n",
    "    shuffle = drop / 100.\n",
    "    blank = drop /100.\n",
    "    drop_prob = drop/50.\n",
    "    new_path = \"multi30k_rsbs\"+str(drop)\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    # 除了 train.en 其他文件copy过来\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            # rep \n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                if not keep[j]:\n",
    "                    rand = np.random.rand()\n",
    "                    if rand >0.66:\n",
    "                        sent.append(w)\n",
    "                        sent.append(w)\n",
    "                    elif rand >0.33:\n",
    "                        sent.append(word_list_all[np.random.randint(0,len(word_list_all))])\n",
    "                    else:\n",
    "                        sent.append('unk')\n",
    "                else:\n",
    "                    sent.append(w)\n",
    "            word_list = sent\n",
    "            # shuffle\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.ceil( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-banana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./multi30k_rsbs50/valid.en'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complicated-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = './multi30k_rsbs0/train.en'\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "with open(ref,'r') as f:\n",
    "    lines = f.readlines()\n",
    "refs = []\n",
    "bleu = {}\n",
    "for line in lines:\n",
    "    refs.append([line.strip().split(' ')])\n",
    "for drop in range(5,55,5):\n",
    "    cands= []\n",
    "    bleu[drop] = []\n",
    "    cand = './multi30k_rsbs'+str(drop)+'/train.en'\n",
    "    with open(cand,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        cands.append(line.strip().split(' '))\n",
    "    for weights in [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]:\n",
    "        bleu[drop].append(corpus_bleu(refs,cands,weights=weights))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sensitive-province",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.904\n",
      "0.82\n",
      "0.726\n",
      "0.643\n",
      "\n",
      "2.0\n",
      "0.814\n",
      "0.488\n",
      "0.316\n",
      "0.206\n",
      "\n",
      "3.0\n",
      "0.731\n",
      "0.334\n",
      "0.165\n",
      "0.081\n",
      "\n",
      "4.0\n",
      "0.654\n",
      "0.248\n",
      "0.097\n",
      "0.038\n",
      "\n",
      "5.0\n",
      "0.582\n",
      "0.181\n",
      "0.056\n",
      "0.017\n",
      "\n",
      "6.0\n",
      "0.514\n",
      "0.128\n",
      "0.029\n",
      "0.007\n",
      "\n",
      "7.0\n",
      "0.451\n",
      "0.091\n",
      "0.015\n",
      "0.002\n",
      "\n",
      "8.0\n",
      "0.391\n",
      "0.065\n",
      "0.007\n",
      "0.001\n",
      "\n",
      "9.0\n",
      "0.336\n",
      "0.046\n",
      "0.003\n",
      "0.0\n",
      "\n",
      "10.0\n",
      "0.282\n",
      "0.034\n",
      "0.002\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bleu_new = {}\n",
    "for key in range(5,55,5):\n",
    "    print(key/5)\n",
    "    for bl in bleu[key]:\n",
    "        print(round(bl*100,2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "metropolitan-scratch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|BLEU-1|90.4|81.4|73.1|65.4|58.2|51.4|45.1|39.1|33.6|28.2|\n",
      "|BLEU-2|82.0|48.8|33.4|24.8|18.1|12.8|9.1|6.5|4.6|3.4|\n",
      "|BLEU-3|72.6|31.6|16.5|9.7|5.6|2.9|1.5|0.7|0.3|0.2|\n",
      "|BLEU-4|64.3|20.6|8.1|3.8|1.7|0.7|0.2|0.1|0.0|0.0|\n"
     ]
    }
   ],
   "source": [
    "for n in [0,1,2,3]:\n",
    "    out = [str(round(bleu[key][n]*100,1)) for key in range(5,55,5)]\n",
    "    print('|BLEU-'+str(n+1)+'|'+'|'.join(out)+'|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acting-worse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64.32, 20.55, 8.15, 3.78, 1.7, 0.66, 0.23, 0.07, 0.02, 0.01]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distant-passenger",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-15a8b9941115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdrop_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multi30k_rsbs\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mnew_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_name' is not defined"
     ]
    }
   ],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "import copy\n",
    "\n",
    "for drop in range(0,55,5):\n",
    "    shuffle = drop / 100.\n",
    "    blank = drop /100.\n",
    "    drop_prob = drop/50.\n",
    "    new_path = \"multi30k_rsbs\"+str(drop)\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    # 除了 train.en 其他文件copy过来\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            # rep \n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                if not keep[j]:\n",
    "                    rand = np.random.rand()\n",
    "                    if rand >0.66:\n",
    "                        sent.append(w)\n",
    "                        sent.append(w)\n",
    "                    elif rand >0.33:\n",
    "                        sent.append(word_list_all[np.random.randint(0,len(word_list_all))])\n",
    "                    else:\n",
    "                        sent.append('unk')\n",
    "                else:\n",
    "                    sent.append(w)\n",
    "            word_list = sent\n",
    "            # shuffle\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.ceil( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graphic-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'straps'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_all[np.random.randint(0,len(word_list_all))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interested-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 397793\n",
      "5 394892\n",
      "10 370088\n",
      "15 352603\n",
      "20 329896\n",
      "25 309223\n",
      "30 291376\n",
      "35 273685\n",
      "40 250221\n",
      "45 233407\n",
      "50 206157\n"
     ]
    }
   ],
   "source": [
    "# word drop\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'wmt18.multi30k.en-de/'\n",
    "for drop in range(40,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    new_path = \"bpe_multi30k_mul\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            drop_num = np.floor(drop_prob * sen_len)\n",
    "\n",
    "            len_left = sen_len - drop_num\n",
    "            \n",
    "            start = np.random.randint(0,len_left)\n",
    "            sent = []\n",
    "            for j, w in enumerate(word_list):\n",
    "                if j >= start and j < start +drop_num:\n",
    "                    continue\n",
    "                sent.append(w)\n",
    "#             sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "flying-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple noise\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'wmt18.multi30k.en-de/'\n",
    "for drop in range(0,55,5):\n",
    "    drop_prob = drop /100.\n",
    "    shuffle = drop / 50.\n",
    "    blank = drop /100.\n",
    "    new_path = \"bpe_multi30k_mul\"+str(drop)\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file or '.ipy' in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "            sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            # 完成 drop\n",
    "            keep = np.random.rand(len(sent)) > blank\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent_blank = []\n",
    "            for j,w in enumerate(sent):\n",
    "                if keep[j]:\n",
    "                    sent_blank.append(w)\n",
    "                else:\n",
    "                    sent_blank.append('unk')\n",
    "            word_list = sent_blank\n",
    "            sent_shuffle = []\n",
    "            shuffle_cnt =np.floor( shuffle * len(word_list))\n",
    "            if shuffle_cnt == 1:\n",
    "                shuffle_cnt = 0\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if shuffle_cnt > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    shuffle_cnt = len(word_list) -1\n",
    "                else:\n",
    "                    shuffle_cnt = 0\n",
    "            for i in range(int(shuffle_cnt)):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "mental-rwanda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "logical-fiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparative-mills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./val/multi30k_blank0.5/valid.en 5 13308\n",
      "./val/multi30k_blank1.5/valid.en 15 13308\n",
      "./val/multi30k_blank2.5/valid.en 25 13308\n",
      "./val/multi30k_blank3.5/valid.en 35 13308\n",
      "./val/multi30k_blank4.5/valid.en 45 13308\n"
     ]
    }
   ],
   "source": [
    "# word blank\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(5,55,10):\n",
    "    new_path = \"val/multi30k_blank\"+str(drop*0.1)\n",
    "    drop_prob = drop  * 0.01\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent = []\n",
    "            for j,w in enumerate(word_list):\n",
    "                if keep[j]:\n",
    "                    sent.append(w)\n",
    "                else:\n",
    "                    sent.append('unk')\n",
    "    #         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(new_file,drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signal-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word shuffle\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(0,11):\n",
    "    new_path = \"val/multi30k_shuffle\"+str(drop)\n",
    "    drop_prob = drop\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "\n",
    "        for line in lines_valid:\n",
    "            drop_prob = drop\n",
    "            sent = []\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            sort = list(range(sen_len))\n",
    "            random.shuffle(sort)\n",
    "            if drop_prob > len(word_list) - 1:\n",
    "                if len(word_list)  >= 2 :\n",
    "                    drop_prob = len(word_list) -1\n",
    "                else:\n",
    "                    drop_prob = 0\n",
    "            for i in range(drop_prob):\n",
    "                tmp = word_list[sort[i]]\n",
    "                word_list[sort[i]] = word_list[sort[i+1]]\n",
    "                word_list[sort[i+1]] = tmp\n",
    "    #         for i, word in enumerate(word_list):\n",
    "    #             sent.append(word_list[sort[i]])\n",
    "            the_file.write(' '.join(word_list)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medieval-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle all\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "drop = 'all'\n",
    "\n",
    "new_path = \"val/multi30k_shuffle\"+str(drop)\n",
    "# List files and directories\n",
    "# in '/home/User/Documents'\n",
    "folder = os.path.exists(new_path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "for file in os.listdir(path):\n",
    "    if file_name in file:\n",
    "        continue\n",
    "    source = os.path.join(path,file)\n",
    "    destination = os.path.join(new_path,file)\n",
    "    if os.path.exists(destination):\n",
    "        continue\n",
    "# Copy the content of\n",
    "# source to destination\n",
    "    dest = shutil.copyfile(source, destination)\n",
    "\n",
    "file = file_name\n",
    "new_file = './'+new_path+'/'+file\n",
    "if os.path.exists(new_file):\n",
    "    os.remove(new_file)\n",
    "with open(new_file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "\n",
    "    for line in lines_valid:\n",
    "        new_word_sent = []\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        for i in range(sen_len):\n",
    "            new_word_sent.append(word_list[sort[i]])\n",
    "        the_file.write(' '.join(new_word_sent)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "egyptian-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 377534\n",
      "2 377534\n",
      "3 377534\n",
      "4 377534\n",
      "5 377534\n",
      "6 377534\n"
     ]
    }
   ],
   "source": [
    "# word sub\n",
    "import os\n",
    "# importing shutil module \n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "# path\n",
    "path = 'ori_multi30k/'\n",
    "for drop in range(1,7):\n",
    "    new_path = \"multi30k_sub\"+str(drop)\n",
    "    drop_prob = drop  * 0.1\n",
    "    # List files and directories\n",
    "    # in '/home/User/Documents'\n",
    "    folder = os.path.exists(new_path)\n",
    "    if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "        os.makedirs(new_path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "    for file in os.listdir(path):\n",
    "        if file_name in file:\n",
    "            continue\n",
    "        source = os.path.join(path,file)\n",
    "        destination = os.path.join(new_path,file)\n",
    "        if os.path.exists(destination):\n",
    "            continue\n",
    "    # Copy the content of\n",
    "    # source to destination\n",
    "        dest = shutil.copyfile(source, destination)\n",
    "\n",
    "    file = file_name\n",
    "    new_file = './'+new_path+'/'+file\n",
    "    if os.path.exists(new_file):\n",
    "        os.remove(new_file)\n",
    "    with open(new_file, 'a') as the_file:\n",
    "        drop_lines = []\n",
    "        sum_len = 0\n",
    "        for line in lines_valid:\n",
    "            word_list = line.split()\n",
    "            sen_len = len(word_list)\n",
    "            keep = np.random.rand(len(word_list)) > drop_prob\n",
    "    #         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "            sent = []\n",
    "            for j,w in enumerate(word_list):\n",
    "                if keep[j]:\n",
    "                    sent.append(w)\n",
    "                else:\n",
    "                    rand = np.random.randint(len(word_list_all))\n",
    "                    sent.append(word_list_all[rand])\n",
    "    #         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "            the_file.write(' '.join(sent)+'\\n')\n",
    "            sum_len+= len(sent)\n",
    "        print(drop,sum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-packet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "divine-graham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asphalt',\n",
       " 'decorated',\n",
       " 'slo@@',\n",
       " 'benches',\n",
       " 'chers',\n",
       " 'gate',\n",
       " 'collared',\n",
       " 'ka@@',\n",
       " 'set',\n",
       " 'wakeboard',\n",
       " 'dding',\n",
       " 'fabri@@',\n",
       " 'toy',\n",
       " 'c-@@',\n",
       " 'pilot',\n",
       " 'boat',\n",
       " 'spre@@',\n",
       " 'potat@@',\n",
       " 'teeth',\n",
       " 'canal',\n",
       " 'visiting',\n",
       " 'dough',\n",
       " 'coffee',\n",
       " 'condu@@',\n",
       " 'cat',\n",
       " 'leggings']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geographic-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file numpy as np\n",
    "import os \n",
    "path = \"multi30k_blank2\"\n",
    "drop_prob = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    for line in lines_valid:\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob\n",
    "#         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        sent = []\n",
    "        for j,w in enumerate(word_list):\n",
    "            if keep[j]:\n",
    "                sent.append(w)\n",
    "            else:\n",
    "                sent.append('<blank>')\n",
    "#         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "        the_file.write(' '.join(sent)+'\\n')\n",
    "        sum_len+= len(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "important-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "path = \"multi30k_shuffle3\"\n",
    "drop_prob = 3\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    \n",
    "    for line in lines_valid:\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        if drop_prob > len(word_list) - 1:\n",
    "            if len(word_list)  >= 2 :\n",
    "                drop_prob = len(word_list) -1\n",
    "            else:\n",
    "                drop_prob = 0\n",
    "        for i in range(drop_prob):\n",
    "            tmp = word_list[sort[i]]\n",
    "            word_list[sort[i]] = word_list[sort[i+1]]\n",
    "            word_list[sort[i+1]] = tmp\n",
    "#         for i, word in enumerate(word_list):\n",
    "#             sent.append(word_list[sort[i]])\n",
    "        the_file.write(' '.join(word_list)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "individual-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "path = \"multi30k_shuffle8_drop2\"\n",
    "drop_prob = 8\n",
    "drop_prob1 = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    \n",
    "    for line in lines_valid:\n",
    "        sent = []\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        sort = list(range(sen_len))\n",
    "        random.shuffle(sort)\n",
    "        if drop_prob > len(word_list) - 1:\n",
    "            if len(word_list)  >= 2 :\n",
    "                drop_prob = len(word_list) -1\n",
    "            else:\n",
    "                drop_prob = 0\n",
    "        for i in range(drop_prob):\n",
    "            tmp = word_list[sort[i]]\n",
    "            word_list[sort[i]] = word_list[sort[i+1]]\n",
    "            word_list[sort[i+1]] = tmp\n",
    "#         for i, word in enumerate(word_list):\n",
    "#             sent.append(word_list[sort[i]])\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob1\n",
    "        sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        the_file.write(' '.join(sent)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "random-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'leans',\n",
       " 'a',\n",
       " 'hawaiian',\n",
       " 'shirt',\n",
       " 'with',\n",
       " 'over',\n",
       " 'the',\n",
       " 'of',\n",
       " 'pilot',\n",
       " 'boat',\n",
       " 'rail',\n",
       " 'fo@@',\n",
       " 'g',\n",
       " 'and',\n",
       " 'mountains',\n",
       " 'in',\n",
       " 'background',\n",
       " '.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vital-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man in shorts and a hawaiian shirt leans over the rail of a pilot boat , with fo@@ g and mountains in the background .\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_shuffle(vocab, x, k):   # slight shuffle such that |sigma[i]-i| <= k\n",
    "    base = torch.arange(x.size(0), dtype=torch.float).repeat(x.size(1), 1).t()\n",
    "    inc = (k+1) * torch.rand(x.size())\n",
    "    inc[x == vocab.go] = 0     # do not shuffle the start sentence symbol\n",
    "    inc[x == vocab.pad] = k+1  # do not shuffle end paddings\n",
    "    _, sigma = (base + inc).sort(dim=0)\n",
    "    return x[sigma, torch.arange(x.size(1))]\n",
    "\n",
    "def word_drop(vocab, x, p):     # drop words with probability p\n",
    "    x_ = []\n",
    "    for i in range(x.size(1)):\n",
    "        words = x[:, i].tolist()\n",
    "        keep = np.random.rand(len(words)) > p\n",
    "        keep[0] = True  # do not drop the start sentence symbol\n",
    "        sent = [w for j, w in enumerate(words) if keep[j]]\n",
    "        sent += [vocab.pad] * (len(words)-len(sent))\n",
    "        x_.append(sent)\n",
    "    return torch.LongTensor(x_).t().contiguous().to(x.device)\n",
    "\n",
    "def word_blank(vocab, x, p):     # blank words with probability p\n",
    "    blank = (torch.rand(x.size(), device=x.device) < p) & \\\n",
    "        (x != vocab.go) & (x != vocab.pad)\n",
    "    x_ = x.clone()\n",
    "    x_[blank] = vocab.blank\n",
    "    return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affiliated-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = line.split()\n",
    "sen_len = len(word_list)\n",
    "keep = np.random.rand(len(word_list)) > drop_prob\n",
    "sent = [w for j, w in enumerate(word_list) if keep[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dated-closing",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-89e7251eea67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "li=list(range(10))\n",
    "random.shuffle(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automotive-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "a=[1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "finnish-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "complete-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'train.tgt'\n",
    "f_valid_en = open('./e2e/e2e-dataset/'+file)\n",
    "lines_valid = f_valid_en.readlines()\n",
    "f_valid_en.close()\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "path = \"e2e_blank2\"\n",
    "drop_prob = 0.2\n",
    "folder = os.path.exists(path)\n",
    "if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "    os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "with open('./'+path+'/'+file, 'a') as the_file:\n",
    "    drop_lines = []\n",
    "    sum_len = 0\n",
    "    for line in lines_valid:\n",
    "        word_list = line.split()\n",
    "        sen_len = len(word_list)\n",
    "        keep = np.random.rand(len(word_list)) > drop_prob\n",
    "#         sent = [w for j, w in enumerate(word_list) if keep[j]]\n",
    "        sent = []\n",
    "        for j,w in enumerate(word_list):\n",
    "            if keep[j]:\n",
    "                sent.append(w)\n",
    "            else:\n",
    "                sent.append('<blank>')\n",
    "#         sent = [word_list[j] for j,k in enumerate(keep) if k else '<blank>']\n",
    "        the_file.write(' '.join(sent)+'\\n')\n",
    "        sum_len+= len(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acute-emphasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aromi', 'is', 'an', 'English', 'restaurant', 'in', 'the', 'city', 'centre.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "numerous-kuwait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aromi', 'is', 'an', 'English', 'restaurant', 'in', 'the', 'city', 'centre.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "regional-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "logits = torch.log_softmax(torch.randn(1, 5),dim=1)*5\n",
    "# Sample soft categorical using reparametrization trick:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bound-christian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.6465,  -2.1335, -12.8090,  -9.1892, -17.3195]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adaptive-toddler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.gumbel_softmax(logits, tau=1.4, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-translation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-study",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
